import type { TransformMessage, XRequestOptions } from '@ant-design/x-sdk';
import { AbstractChatProvider, AbstractXRequestClass } from '@ant-design/x-sdk';
import { sendChatRequest, type ChatRequestParams, type ChatResponse } from '@/utils/request';

export interface MockInput {
  message: {
    role: string;
    content: string;
  };
  userAction?: string;
  model?: string;
}

export interface MockOutput {
  text?: string;
  ext_text?: string;
}

export interface MockMessage {
  content: MockOutput;
  role: string;
}

// ==================== Mock Request ====================
export class MockRequest<
  Input extends MockInput = MockInput,
  Output extends MockOutput = MockOutput,
> extends AbstractXRequestClass<Input, Output> {
  _isTimeout = false;
  _isStreamTimeout = false;
  _isRequesting = false;
  _abortController: AbortController | null = null;

  get asyncHandler(): Promise<void> {
    return Promise.resolve();
  }

  get isTimeout(): boolean {
    return this._isTimeout;
  }

  get isStreamTimeout(): boolean {
    return this._isStreamTimeout;
  }

  get isRequesting(): boolean {
    return this._isRequesting;
  }

  get manual(): boolean {
    return true;
  }

  run(params?: Input | undefined): void {
    this._isRequesting = true;
    // åˆ›å»ºæ–°çš„ AbortController
    this._abortController = new AbortController();
    const { callbacks } = this.options;
    const userMessage = params?.message?.content || '';
    // ä»paramsä¸­è·å–æ¨¡å‹å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    const model = params?.model || 'gpt-3.5-turbo';

    // ä½¿ç”¨æŒ‡å®šçš„ API æ¥å£è·å– AI å›å¤
    const fetchAIResponse = async () => {
      try {
        const requestParams: ChatRequestParams = {
          model,
          messages: [
            {
              role: 'user',
              content: userMessage
            }
          ],
          stream: true // å¯ç”¨æµå¼è¾“å‡º
        };

        let accumulatedText = '';

        // ä½¿ç”¨sendChatRequestå‡½æ•°å‘é€èŠå¤©è¯·æ±‚ï¼Œä¼ å…¥signal
        await sendChatRequest(
          requestParams,
          (chunk: ChatResponse) => {
            const content = chunk.choices[0]?.delta?.content || '';
            if (content) {
              accumulatedText += content;
              // ç›´æ¥è°ƒç”¨onUpdateï¼Œç¡®ä¿å®æ—¶æ›´æ–°
              callbacks?.onUpdate?.({ text: content } as Output, new Headers());
            }
          },
          this._abortController?.signal
        );

        callbacks?.onSuccess?.([{ text: accumulatedText }] as Output[], new Headers());
        this._isRequesting = false;
      } catch (error: any) {
        // æ£€æŸ¥æ˜¯å¦æ˜¯ç”¨æˆ·ä¸»åŠ¨ä¸­æ­¢
        if (error.name === 'AbortError') {
          console.log('Request aborted by user');
          callbacks?.onError?.(new Error('Request aborted'));
        } else {
          console.error('Error fetching AI response:', error);
          callbacks?.onError?.(error as Error);
        }
        this._isRequesting = false;
      }
    };

    fetchAIResponse();
  }

  abort(): void {
    if (this._abortController) {
      this._abortController.abort();
      this._abortController = null;
    }
    this._isRequesting = false;
  }
}

// ==================== Mock Provider ====================
export class MockProvider<
  ChatMessage extends MockMessage = MockMessage,
  Input extends MockInput = MockInput,
  Output extends MockOutput = MockOutput,
> extends AbstractChatProvider<ChatMessage, Input, Output> {
  private model: string;

  constructor(options: any, model?: string) {
    super(options);
    this.model = model || 'gpt-3.5-turbo';
  }

  transformParams(requestParams: Partial<Input>, options: XRequestOptions<Input, Output>): Input {
    if (typeof requestParams !== 'object') {
      throw new Error('requestParams must be an object');
    }
    if (requestParams.userAction === 'retry') {
      const messages = this.getMessages();
      const queryMessage = (messages || [])?.reverse().find(({ role }) => {
        return role === 'user';
      });
      return {
        message: queryMessage ? { role: queryMessage.role, content: queryMessage.content as string } : { role: 'user', content: '' },
        model: this.model, // ä½¿ç”¨å­˜å‚¨çš„æ¨¡å‹å‚æ•°
        ...(options?.params || {}),
        ...(requestParams || {}),
      } as Input;
    }

    return {
      model: this.model, // ä½¿ç”¨å­˜å‚¨çš„æ¨¡å‹å‚æ•°
      ...(options?.params || {}),
      ...(requestParams || {}),
    } as Input;
  }

  transformLocalMessage(requestParams: Partial<Input>): ChatMessage {
    return requestParams.message as unknown as ChatMessage;
  }

  transformMessage(info: TransformMessage<ChatMessage, Output>): ChatMessage {
    const { originMessage, chunk } = info || {};
    if (!chunk) {
      return {
        content: originMessage?.content || {},
        role: 'assistant',
      } as ChatMessage;
    }

    const content = originMessage?.content || {};
    return {
      content: {
        text: (content.text || '') + (chunk.text || ''),
        ext_text: (content.ext_text || '') + (chunk.ext_text || ''),
      },
      role: 'assistant',
    } as ChatMessage;
  }
}

/**
 * ğŸ”” Please replace the BASE_URL, MODEL with your own values.
 */
export const providerCaches = new Map<string, MockProvider>();
export const providerFactory = (conversationKey: string, model?: string) => {
  const cacheKey = `${conversationKey}-${model}`; // ä½¿ç”¨conversationKeyå’Œmodelçš„ç»„åˆä½œä¸ºç¼“å­˜é”®
  if (!providerCaches.get(cacheKey)) {
    providerCaches.set(
      cacheKey,
      new MockProvider({
        request: new MockRequest('Mock Client', {}),
      }, model), // å°†æ¨¡å‹å‚æ•°ä¼ é€’ç»™MockProvider
    );
  }
  return providerCaches.get(cacheKey);
};
